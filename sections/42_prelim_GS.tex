%!TEX root = ../main.tex

\section{Gaussian Splatting}\label{sec:GS}

\subsubsection{3D Gaussian Splatting}\label{sec:3DGS}

\missingfigure{3DGSの図。3DGSのパイプラインの図}

\missingfigure{NeRFと3DGSの分類図。レンダリング速度と、データサイズの2Dプロット。Barronさんのレクチャー動画から。学習速度も入れれば、2次元に収まらない。。2個いるかな? できれば、MVSとかも含めて示せればいい。それだったら表が美しい}

3D Gaussian Splatting (3DGS) は、新規視点合成において最先端(SOTA)の結果を達成している近年の手法である \parencite{Kerbl2023ToG_3DGS}。
その特徴は、フォトリアリスティックかつ高忠実度な3次元シーンのキャプチャ能力、高速な学習時間、そしてリアルタイムレンダリングにある。
明示的な(Explicit)3次元表現である3DGSは、Visual-SLAM \parencite{Yan2024CVPR_GS-SLAM,Zheng2025CVPR_WildGS-SLAM,Matsuki2024CVPR_GaussianSplattingSLAM}、アバター生成 \parencite{Moreau2024CVPR_HumanGaussianSplatting,Shao2024CVPR_GaussianAvatar}、フィードフォワード型3次元再構成 \parencite{Chen2024ECCV_MVSplatting} など、幅広いタスクへの適用に成功している。
その可能性はさらに広がり、衛星画像からの数値表層モデル(DSM)生成 \parencite{Aira2025CVPR_EOGS}、自動運転、そして水中3次元再構成 \parencite{li20243DV_watersplatting} といった様々な実世界アプリケーションへと拡張されている。

\missingfigure{GSが実際に楕円体のプリミティブで構成されていることを示す図。これは自分の発表で使用した寮の中庭の画像でいいかな}

3DGSのパイプラインは主に、レンダリングを行うフォワードパスと、最適化を行うバックワードパスの2つの段階で構成される。
フォワードパスでは、3次元ガウス分布(3D Gaussians)の集合をラスタライズして画像を合成する。
各ガウス分布は、
中心位置 $\bm{p} \in \mathbb{R}^3$、
不透明度 $\alpha \in [0, 1]$、
球面調和関数(SH)によって表現される視点依存の色係数 $\bm{c}(\bm{p}, \bm{t}_i) \in \mathbb{R}^{3}$、
および3次元共分散行列 $\bm{\Sigma}^{\mathrm{3D}} \in \mathbb{R}^{3 \times 3}$ 
という、最適化可能なパラメータセットによって定義される。
共分散行列 $\bm{\Sigma}^{\mathrm{3D}}$ は、スケーリングベクトル $\bm{s} \in \mathbb{R}^3$ から構成されるスケーリング対角行列 $\bm{S} \in \mathbb{R}^{3 \times 3}$ と、回転クォータニオン(回転行列 $\bm{R} \in SO(3)$ として表現)を用いて以下のように構成される：
\begin{equation}\label{eq:3dgs-sigma_RssR}
  \bm{\Sigma}^{\mathrm{3D}} = \bm{R} \bm{S} \bm{S}^\top \bm{R}^\top
\end{equation}
点 $\bm{x} \in \mathbb{R}^3$ に対する対応する非正規化ガウス分布関数は以下で与えられる：
\begin{equation}\label{eq:3dgs-G(x)}
  G(\bm{x}) = 
    \exp \left( -\frac{1}{2} (\bm{x} - \bm{p})^T \left({\bm{\Sigma}^{3D}}\right)^{-1} (\bm{x} - \bm{p}) \right)
\end{equation}
フォワードパスにおいて、あるカメラ視点からの画像をレンダリングするために、これらのガウス分布はまず外部パラメータ行列 $[\bm{W} | \bm{t}]$ を用いてワールド座標系からカメラ座標系へと変換される。
ここで、$\bm{W}_\mathrm{view} \in \mathbb{R}^{3 \times 3}$ は視点回転行列、
$\bm{t} \in \mathbb{R}^3$ は平行移動ベクトルである。
ガウス分布の中心位置 $\bm{p}$ と3次元共分散行列は以下のように更新される：
\begin{align*}
  &\bm{p}_\mathrm{cam} = \bm{W}\bm{p} + \bm{t} \\
  &\bm{\Sigma}^{3D}_\mathrm{cam} = \bm{W} \bm{\Sigma}^{3D} \bm{W}^\top
\end{align*} 
\cite{Zwicker2001_EWA-volume-splatting} の提案した射影手法に従い、カメラ空間における3次元共分散行列 $\Sigma_{cam}^{3D}$ は2次元画像平面へと射影される。
これは透視投影の一次近似(アフィン近似)のヤコビ行列 $\bm{J}$ を用いて行われ、2次元共分散行列 $\bm{\Sigma}^{\mathrm{2D}}$ が得られる：
\begin{equation}\label{eq:3dgs-affine-projection}
\Sigma^\mathrm{2D} = \bm{J} \Sigma^{\mathrm{3D}}_\mathrm{cam} \bm{J}^\top
\end{equation}
各ピクセルの最終的なRGB値 $\bm{\Gamma} \in \mathbb{R}^{3}$ は、射影されたガウス分布をアルファブレンディングすることでレンダリングされる。
ピクセルと重なるガウス分布の集合は、まず深度に基づいて手前から奥へとソートされ、視点依存色が以下のように累積される：
\begin{align}\label{eq:3dgs-alpha-blending}
  \bm{\Gamma}(\bm{x}) = \sum_{k=1}^{K} \bm{c}_k \alpha^{\text{pixel}}_k \prod_{j=1}^{k-1} (1-\alpha^{\text{pixel}}_j) \\
  \quad \text{where} \quad \alpha^{\text{pixel}}_k = \alpha_k G_k^{\mathrm{2D}} \notag
\end{align}
ここで、$k$ はピクセルに重なる整列されたガウス分布の集合のインデックスである。

バックワードパスでは、最適化により測光誤差(Photometric loss)を最小化する。
これは $\mathcal{L}_1 (\Gamma, \Gamma_{gt})$ 損失と D-SSIM 損失 $\mathcal{L}_\mathrm{D-SSIM} (\Gamma, \Gamma_{gt})$ \parencite{Zhou2004_SSIM} の加重和である：
\begin{equation}\label{eq:loss-function}
  \mathcal{L} = (1 - \lambda) \mathcal{L}_1 + \lambda \mathcal{L}_\mathrm{D-SSIM}
\end{equation}
したがって、最適化問題は以下のように定式化される：
\begin{equation}\label{eq:optimization}
  \underset{p, R, s, c, \alpha}{\textrm{argmin}} \quad \mathcal{L} = \mathcal{L}(\bm{\Gamma}, \bm{\Gamma_{gt}}) 
\end{equation}
これらの定式化により、パイプライン全体が完全微分可能となり、パラメータ $\Theta = \{\bm{p}, \bm{R}, \bm{s}, \bm{c}, \alpha\}$ は勾配降下法によって最適化可能となる。
% Adam \parencite{Adam} を用いた~ と言っていたがこれは、Implplementationで言及すること
その最適化に要する学習時間は、30kのイテレーションによって1時間以内となり、当時NVSのSotaであったMip-NeRF360 \parencite{Barron2022CVPR_Mip-NeRF360} に比較して10倍以上の高速化を達成した。
加えて、Ray-Tracingに比較し、既存のGPU描画パイプラインの性能を引き出すTile-Basedレンダリングによって、100 fps以上のリアルタイムレンダリングを実現したことで、インタラクティブなSceneの可視化が可能となった。
このプロセスを通じて得られた3次元ガウス分布の集合は、3次元シーンを高忠実度で捉えることができる。


しかし、このパイプライン全体はピンホールカメラモデルと透視投影に依存しており、光が直線的に進むことを根本的な前提としている。
この前提は、空気と水の境界での屈折が深刻な幾何学的矛盾を引き起こし、再構成の失敗につながるような、複数の媒質が介在する環境においては成立しない。

この制限にもかかわらず、3DGSはNeRFのような陰的表現(Implicit representations)と比較して、この課題に対処するのに独自に適している。
これは、ガウスプリミティブの明示的な性質が、直接的な物理モデリングに対して非常に開放的であるためである。
これにより、屈折の法則を数学的に定式化し、シーン表現の幾何学的パラメータそのものに直接適用することが可能となる。


\subsection{2D Gaussian Splatting}\label{sec:2DGS}
不透明度 $\alpha_i$ の計算方法が3DGSとは異なる点です。
2DGSでは、レイとプリミティブ $k$ の平面との交点 $\mathbf{p}_{inter}$ を求め、その交点の「ガウス中心からのローカル座標系での距離」に基づいて評価します。




2DGSにおいて、シーンは配向された平らな2次元ガウス分布(Surfel)の集合として表現される。
ピクセル座標 $(u, v)$ を通過する視線(Ray) $\bm{r}(t) = \bm{o} + t\bm{d}$ は、深度順にソートされた $N$ 個のガウス平面と交差し、その交点における評価値が画像形成に寄与する。

\section{返り値の数理的解析}

\subsection{レンダリングされた色 (\texttt{render\_colors})}
\textbf{型:} $[..., C, H, W, 3]$ (RGB)

これはボリュームレンダリング方程式の離散化表現である。色は以下のFront-to-backアルファブレンディングにより計算される。

\begin{equation}
    C(\mathbf{r}) = \sum_{i \in \mathcal{N}} c_i \alpha_i T_i, \quad T_i = \prod_{j=1}^{i-1} (1 - \alpha_j)
\end{equation}

ここで、透過率 $T_i$ はレイが $i$ 番目のガウス分布に到達する確率を表す。
2DGSの特異性は不透明度 $\alpha_i$ の導出にある。レイと第 $k$ プリミティブ平面との交点 $\bm{p}_{inter}$ をローカル座標系へ変換した変位ベクトルを $\bm{u}$ とすると、$\alpha_i$ は以下のように定義される。

\begin{equation}
    \alpha_i = o_i \exp\left( -\frac{1}{2} \bm{u}^\top \bm{\Sigma}_{2D}^{-1} \bm{u} \right)
\end{equation}

ここで、$o_i$ は学習可能な不透明度パラメータ、$\bm{\Sigma}_{2D}$ は2次元スケーリングと回転行列から構成される局所的な分散行列である。

\subsection{蓄積アルファ (\texttt{render\_alphas})}
\textbf{型:} $[..., C, H, W, 1]$

レイに沿った総不透明度であり、物理的にはレイが物体によって遮蔽された確率を表す。これは最終的な透過率 $T_{final}$ の補数となる。

\begin{equation}
    A(\mathbf{r}) = \sum_{i \in \mathcal{N}} \alpha_i T_i = 1 - T_{final} = 1 - \prod_{i=1}^{N} (1 - \alpha_i)
\end{equation}

\subsection{ボリューム法線 (\texttt{render\_normals})}
\textbf{型:} $[..., C, H, W, 3]$

2DGSが「幾何学的に正確」であるための核心的な項である。各2次元ガウス円盤の固有法線 $\bm{n}_i$ を、色情報と同様の重みでブレンディングしたものである。

\begin{equation}
    \bm{n}_{vol}(\bm{r}) = \sum_{i \in \mathcal{N}} (\bm{R}_i \cdot \bm{z}_{local}) \alpha_i T_i
\end{equation}

ここで $\bm{R}_i$ はクォータニオンから導出される回転行列、$\bm{z}_{local} = (0,0,1)^\top$ はローカル座標系における法線ベクトルである。この $\bm{n}_{vol}$ は、後述する表面法線との整合性を取る正則化(Normal Consistency Loss)に使用される。

\subsection{表面法線 (\texttt{surf\_normals})}
\textbf{型:} $[..., C, H, W, 3]$

レンダリングされた深度マップの幾何学的勾配から算出される法線であり、「見かけ上の形状」を表す。まず、期待値深度(Expected Depth) $D(u,v)$ を計算する。

\begin{equation}
    D(u, v) = \sum_{i \in \mathcal{N}} t_i \alpha_i T_i
\end{equation}

ここで $t_i$ はカメラ原点から交点までの距離である。$\bm{n}_{surf}$ は画像空間における勾配のクロス積として近似される。

\begin{equation}
    \bm{n}_{surf} \propto \frac{\partial D}{\partial u} \times \frac{\partial D}{\partial v}
\end{equation}

\subsection{歪み (\texttt{render\_distort})}
\textbf{型:} $[..., C, H, W, 1]$

Mip-NeRF 360で提案されたDistortion LossのL1変種である。レイ上の密度分布が局所的に集中(＝明確な表面が存在)することを奨励する。

\begin{equation}
    \mathcal{L}_{dist}(\bm{r}) = \sum_{i, j} w_i w_j |t_i - t_j| + \frac{1}{3} \sum_i w_i^2 s_i
\end{equation}
(ただし実装上は計算効率化のため、上記式の簡易版が用いられる場合がある)

\subsection{中央値深度 (\texttt{render\_median})}
\textbf{型:} $[..., C, H, W, 1]$

累積透過率が閾値0.5に達した地点の深度。期待値深度におけるエッジ付近のアーティファクト(Flying Pixels)を抑制し、TSDF Fusion等によるメッシュ再構成において堅牢な結果を提供する。

\begin{equation}
    t_{median} = \mathop{\mathrm{argmin}}_t \left| \int_{0}^{t} \alpha(s)T(s) \mathrm{d}s - 0.5 \right|
\end{equation}

\section{実装上の設計指針 (Engineering Advice)}

Google Researchの実装経験に基づき、安定したパイプライン構築のための重要な指針を以下に示す。

\subsection{Ray-Plane Intersectionの特異点処理}
視線ベクトル $\bm{d}$ と平面法線 $\bm{n}_i$ が直交に近い場合(Grazing Angle)、交点計算は数値的に不安定となる。CUDAカーネル内では、内積値に対するハードクリッピングを推奨する。

\begin{equation}
    \text{if } |\bm{d} \cdot \bm{n}_i| < \epsilon \quad (\text{e.g., } \epsilon=0.05), \quad \text{discard intersection.}
\end{equation}

\subsection{幾何再構成のための深度モード}
メッシュ抽出を目的とする場合、\texttt{depth\_mode}の選択は重要である。浮遊ノイズの少ない高品質なメッシュを得るためには、\texttt{render\_median} の出力を信頼するか、あるいは正則化項を含んだ \texttt{RGB+ED} モードでの学習結果を用いることが望ましい。また、微分可能レンダリングにおいて \texttt{surf\_normals} を利用する際は、計算グラフの切断(detach)を適切に管理する必要がある。