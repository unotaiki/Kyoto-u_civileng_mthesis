%!TEX root = ../main.tex
\chapter{背景理論}\label{chap:prelim_3d-reconstruction-from-images}

\section{画像に基づく3次元復元 (3D Reconstruction from Images)}\label{sec:prelim_3d-reconstruction-from-images}
画像を用いた測量は写真測量(Photogrammetry)と呼ばれ、古い歴史あり。
\url{https://duplicate-3d.com/rd/2025-09-11-photogrammetry-history/} この記事を参考に。
もともとは専門的な技能を持った人が、専用の機械(?)を用いて作成。

画像のデジタル化、イメージセンサの発明によりコンピュータビジョン（Computer Vision, CV）が始まる。
Image Sensorから得た視覚情報から、人間や他の生物と同じようにComputerやMachineにSceneを理解させる。

画像センサ（Image Sensor）が捉える情報は、本質的には3次元シーンから2次元平面への射影（Projection）である。
この過程において、3次元空間の奥行き情報は1次元分欠落し、情報の「縮退」が発生する。
3次元復元の主眼は、この失われた次元を幾何学的制約や事前知識（Priors）を用いて補完し、元のシーンの構造を逆問題として解くことにある。
3次元情報は生物が自己が生きる世界を認識、理解するうえで必須の情報であり、ロボットの自己位置推定、環境認識などにも多大なニーズがあり、Computer Visionの主要タスクとして数多くの研究がなされ、今もめちゃくちゃレッドオーシャン。

古くから、単眼画像から形状を推定する手法として、輝度やテクスチャ、影などの手掛かりを利用する \textit{Shape from X}（$X \in \{\text{shading, Silhouette, Texture, Focus, etc.}\}$）の研究が行われてきた。
しかし、より頑健な復元を行うためには、視点移動を伴う複数枚の画像、あるいは動画（Image sequence）を用いて幾何的な整合性を元に手法が主流となった。
この手法、タスクの総称を Structure from Motion (SfM) と呼ぶ。
このSfMを起点とする、3D Vision for Geometry手法の発達、高度なUIを備えた商用ソフト(Pix4D, Metashape, etc.)の出現、オープンソース化により、今日ではPhotogrammetry技術は広く一般に普及した。

\subsection{Structure from Motion}
SfMは、複数の視点から撮影された画像群に基づき、カメラの内部・外部パラメータ（三次元的な動き）と、シーンの疎な（Sparse）3次元構造を同時に推定する手法である。
Tomasi-Kanadeによる行列分解法に始まる。
HartleyやZissermanら(2000年代)によって幾何学的理論の基礎が確立された。 (VGGTのYoutubeの対談動画で取り上げられていた。もう少し詳しくは、Harley先生たちの本を参照。)
2016年に発表された COLMAP は、高い精度と汎用性、そしてOpen Sourceのプロジェクトとしての完成度から現在でもアカデミック分野でデファクトスタンダードとして広く利用されている。
\checkref{COLMAPでは、Pixel wiseなんちゃらで、MVSの新規研究も実装されている}
また、COLMAPにより出力される、正確なカメラ内部パラメータ(Intrinsic)と外部パラメータ(Extrinsic)は、歪みのない画像(Undistorted Images)は、後述するDense Reconstruction や 新規視点合成タスク のための入力データとして、重要なパイプラインの一角を担っている。

In a typical incremental SfM pipeline, keypoints are firstly detected and matched across frames using feature detectors and descriptors such as SIFT \parencite{Lowe2004_SIFT}.
Fundamental matrix $F$ between two images is then calculated, commonly via eight-points algorithm \parencite{Hartley1997_8PointAlgorithm} combined with random sample consensus (RANSAC) \parencite{Fischler1987_RANSAC}, which lead to camera pose recovery through singular value decomposition.
New camera poses are iteratively registered via Perspective-n-Point algorithms, which align estimated 3D points with 2D features in new frames.
Triangulation is subsequently applied to obtain additional 3D points from feature correspondences, and bundle adjustment (BA) \parencite{Triggs2000_BA} is finally performed to minimize reprojection error, refining both camera parameters and 3D points. 
画像を貼るぞい!!!http://theia-sfm.org/sfm.html

\begin{figure}[htbp]
  \centering
  \captionsetup{justification=raggedright}
  \includegraphics[width=0.7\linewidth]{figure/40_prelim/sfm_pipeline.png}
  \caption{SfM Pipeline \cite{fig:Theia-SfM}}
  \label{fig:sfm_pipeline}
\end{figure}

\subsection{Multi-View Stereo}
\note{無駄に力入れて書きすぎ。MVSとかほとんど本題じゃない。むしろSfMを頑張って記述するべきだった。(いい勉強になったが)、Appendixに回した方がいいげ}
SfMなどによって得られたカメラパラメータが既知の多視点画像郡から、各画素単位で密な深度推定により、高密度な三次元復元を行うのが Multi-View Stereo (MVS) である。
SfMの出力三次元情報が疎な(Sparse)点群であるのに対して、MVSは物体表面の密な(Dense)な三次元点群やメッシュ(Mesh)を推定することから、MVSは Dense 3D Reconstruction (密な三次元再構成)のタスクを行っていると言える。
これを達成するため、各画素における深度(Depth)や法線(Normal)といった幾何パラメータを、画像間の整合性(Photometric Consistency)に基づいて最適化する手法がとられる。
本節では、パッチベース手法の古典であるPMVS \cite{Furukawa2010_PatchMVS} の概念を概観した後、現在のデファクトスタンダードなパイプライン（COLMAP \cite{Schnberger2016ECCV_PatchMatchStereo}）の基礎となっているPatchMatch Stereoについて詳述する。


\missingfigure{MVSがSfMに続くパイプラインで構成されていることを示す図。フィックスターズの表す図を参考に}


% --- PMVS ---
\textbf{PMVS}: 

\subsubsection{Patch-based Multi-View Stereo (PMVS)}

\begin{figure}
  \centering
  \captionsetup{justification=raggedright}
  \includegraphics[width=0.8\linewidth]{figure/40_prelim/PMVS.png}
  \caption{PMVS Pipeline。 \cite{fig:Theia-SfM}から引用。 
  左から右にかけてそれぞれの画像は、(1) 入力された多視点画像の一例; (2) 検出された特徴点; (3) 初期マッチング後のパッチ; (4) 拡張とフィルタリング後のパッチ; (5) メッシュモデル.}
  \label{fig:pmvs_pipeline}
\end{figure}

\cite{Furukawa2010_PMVS} によって提案された Patch-based Multi-View Stereo (PMVS) は、物体表面を微小な平面パッチの集合としてモデル化し、これを拡張・最適化することで密な3次元形状を復元する手法である。
本手法は、特徴点マッチングによる疎な初期復元から出発し、信頼度の高いパッチを周囲に拡張(Expand)していくアプローチをとる、物体表面の形状を密に3次元推定するための先駆的かつ代表的な手法である。
\checkref{cite{}では、現在の設定では名前が表示されずただ、[8]のように番号のみになるため、別の方法や引用のフォーマットの設定を考える}

PMVSにおける基本単位であるパッチ $B$ は、単なる画像の矩形領域ではなく、対象物体の表面に接する微小平面（局所接平面）の近似として定義される。
パッチ $B$ は以下のパラメータを持つ。
\begin{itemize}
    \item \textbf{中心座標} $\bm{p_B} \in \mathbb{R}^3$: パッチの中心位置。
    \item \textbf{法線ベクトル} $\mathbf{n_B} \in \mathbb{R}^3$: パッチの向きを表す単位法線ベクトル。
    \item \textbf{参照画像} $R_B$: パッチ $B$ を観測する画像の中で、光学的・幾何的に最も適した画像。
    \item \textbf{可視画像集合} $V_B$: パッチ $B$ がオクルージョンなく観測可能であり、かつ相関スコアが閾値以上となる画像の集合。
\end{itemize}

PMVSの処理は、特徴点からの初期化(Initialization)の後、以下の3つのステップ、拡張(Expansion)、フィルタリング(Filtering)、最適化(Optimization)を反復することで行われる。

\begin{enumerate}
    \item \textbf{Initialization (初期化)}:
    SfMと同様に、各画像から特徴点検出･マッチングを行う\cite{Lowe2004_SIFT}。
    ここから得られる疎な点群をSeed Patchとして、初期の法線とともに最初のパッチ郡を生成するよ。
    前処理としてカメラパラメータの取得にSfMを用いている場合、これらの特徴点と、Triangulation(三角測量)によって得られる疎な三次元点群はそのまま使用できる。

    \item \textbf{Expansion (拡張)}:
    物体の表面が滑らかに連続しているという仮定に基づき、パッチをシーンの表面に沿うように増殖させていく。
    既存のパッチ $B$ を参照画像 $R_B$ および可視画像集合 $V_B$ に投影し、その隣接画素に対応する空間領域にパッチが存在しない場合、新たなパッチ $B'$ を生成する。
    この際、親パッチ $B$ の法線 $\mathbf{n_B}$ と深さ情報を初期値として継承させることで、テクスチャが弱い領域であっても、隣接する確度の高い領域から表面を「張り出して」いくことが可能となる。

    \item \textbf{Filtering (フィルタリング)}:
    拡張プロセスによって生じた誤ったパッチを除去する。以下の3つの基準が主に用いられる。
    \begin{itemize}
        \item \textbf{Visibility Consistency}: 複数のパッチが同一の視線上に存在する場合、カメラに近い方を残し、隠蔽される奥のパッチを削除する。
        \item \textbf{Photometric Consistency}: 正規化相互相関 (NCC) 等を用いた画像間の整合性スコアが一定以下のパッチを外れ値として破棄する。
        \item \textbf{Number of Views}: パッチを安定して観測できるカメラの台数 $|V(p)|$ が最小閾値未満のものを信頼性不足として削除する。
    \end{itemize}

    \item \textbf{Optimization (最適化)}:
    各パッチの位置 $\bm{p_B}$ と法線 $\mathbf{n_B}$ を微修正し、画像間の整合性を最大化する。
    具体的には、パッチ $B$ を可視画像 $I \in V_B$ へ投影して得られる画素値と、参照画像 $R_B$ 上の画素値との間のPhotometric Discrepancyを最小化するように、非線形最適化を行う。
    \begin{equation}
      g(p) = \frac{1}{|V(B) \setminus R(B) |} \sum_{I \in V(B), I \neq R(B)} \text{g}(B, I, R(B))
    \end{equation}
    ここで,$\text{g}(B, I_1, I_2)$は、パッチ$B$に対する、画像$I_1$と$I_2$の間のPhotometric Discrepancyを測定するための関数であり、NCCなどを使用することができる。
    \rewrite{Photometric Discrepancyを日本語で説明すると、}
    この際、パッチの法線 $\mathbf{n}(p)$ を考慮して各画像をホモグラフィ変換することで、視点による透視歪みを補正し、より正確なマッチングを実現している。
\end{enumerate}

以上のプロセスを収束するまで繰り返すことで、初期の疎な点群は徐々に密度を増し、最終的に物体表面全体を覆う密な点群が得られる。
\cite{Furukawa2010_PMVS} の手法は、大域的な最適化を行うPatchMatch Stereo等と比較して局所的な貪欲法に近い性質を持ち、計算コストが高いが、拡張ステップによる表面の連続性利用が強力であり、密な復元を実現するための歴史的に重要な手法である。


% --- PatchMatch Stereo ---
\subsection{PatchMatch Stereo}

PMVSが、信頼できる「種（Seed）」から局所的に表面を拡張していくアプローチであるのに対し、\cite{Bleyer2011BMVC_PatchMatchStereo} が提案した PatchMatch Stereo は、画像上のすべての画素に対して、個別の3次元平面パラメータ（深度と法線）を推定する手法である。

従来の局所ステレオマッチング手法は、マッチングウィンドウ内の深度が一定である（カメラに対して平行な平面：Fronto-parallel window）と仮定することが一般的であった。
しかし、この仮定は傾いた面や曲面において成立せず、再構成精度の低下や「階段状」のアーティファクトを生む原因となっていた。
これに対し、Bleyerらは各画素のウィンドウを3次元空間内の傾いた平面（Slanted Support Window）としてモデル化した。
しかし、各画素に対して最適な平面パラメータ（深度および法線の向き）を決定しようとすると、その探索空間は連続値であり無限大となるため、従来の総当たり的な探索や離散ラベルを用いる手法（Graph Cutsなど）は適用できない。

この問題を解決するために導入されたのが、Barnesらによる最近傍探索アルゴリズム "PatchMatch" の概念をステレオ視に応用した推論フレームワークである。
\note{元論文をよりしっかり読み込む。正しいか?}

\textbf{平面モデルとマッチングコスト}:
左画像の各画素 $\Gamma$ に対し、3次元平面 $f_\Gamma$ を割り当てる。
平面 $f_\Gamma$ は3つのパラメータ $(a_{f_\Gamma}, b_{f_\Gamma}, c_{f_\Gamma})$ を持ち、画素 $\Gamma$ の座標 $(\Gamma_x, \Gamma_y)$ における深度 $d_\Gamma$ は以下の式で表される。
\begin{equation}
    d_\Gamma = a_{f_\Gamma} \Gamma_x + b_{f_\Gamma} \Gamma_y + c_{f_\Gamma}
\end{equation}
このモデルにより、画素ごとに異なる法線を持つ傾いた平面を表現でき、サブピクセル精度の深度推定が可能となる。
最適化の目的は、各画素 $\Gamma$ において、アグリゲーションコスト $m(\Gamma, f_\Gamma)$ を最小化する平面 $f_\Gamma$ を、無限の候補空間 $\mathcal{F}$ から見つけ出すことである。
\begin{equation}
    f_\Gamma = \operatorname*{argmin}_{f \in \mathcal{F}} m(\Gamma, f_\Gamma)
\end{equation}

\textbf{ランダム探索と伝播による推論}: 
PatchMatch Stereoの核心は、ランダムな初期化状態から、空間的・視点的な相関を利用して「良い解」を画像全体に伝播(Propagate)させるプロセスにある。
アルゴリズムは、以下のステップを反復することで収束する。

\begin{enumerate}
    \item \textbf{Random Initialization (ランダム初期化)}:
    初期状態では、すべての画素に対し、ランダムなパラメータを持つ平面（ランダムな深度と法線ベクトル）を割り当てる。

    \item \textbf{Spatial Propagation (空間伝播)}:
    「隣接する画素は、同じ平面上に乗っている可能性が高い」という仮定を利用する。
    画像走査順序に従い、現在の画素 $\Gamma$ とその近傍画素 $\Gamma'$（例えば左上の画素）を比較する。
    もし、近傍画素 $\Gamma'$ の持つ平面 $f_{\Gamma'}$ を画素 $\Gamma$ に適用した際のマッチングコストが、現在の平面 $f_\Gamma$ よりも低くなるならば、画素 $\Gamma$ は平面 $f_{\Gamma'}$ を自身の新たな推定値として採用し、コピーする。
    これにより、画像の一部で偶然「正解に近い平面」が見つかれば、その平面情報は波紋のように隣接画素へと広がり、領域全体が正しい平面で埋め尽くされていく。

    \item \textbf{View Propagation (視点間伝播)}:
    ステレオ特有の拡張として、左右画像間の一貫性を利用する。
    左画像の画素 $\Gamma$ の対応点である右画像の画素 $\Gamma'$ が、より適切な平面パラメータを持っている場合、それを左画像座標系へ変換して取り込む。これにより、オクルージョン領域外での整合性が強力に担保される。

    \item \textbf{Plane Refinement (平面の微調整)}:
    伝播のみでは、既存の平面パラメータのコピーしか行われないため、真値へ到達できない。そこで、現在の平面パラメータに微小なランダム摂動（Perturbation）を加え、コストが改善するかをテストする。反復が進むにつれて摂動の範囲を指数関数的に狭めていくことで、サブピクセルレベルでの高精度な収束を実現する。
\end{enumerate}

\missingfigure{イシグロが良く示している収束を示す図を追加}

この手法の利点は、巨大なコストボリューム（Cost Volume）をメモリ上に構築する必要がないため、高解像度画像や大きな視差範囲に対してもメモリ効率が良い点にある。
また、連続空間での最適化を行うため、離散化に伴う量子化誤差が発生せず、極めて滑らかな曲面や急峻な傾斜面の復元に成功している。

\note{Pixel wise View Selectionが、この手法をいかにMVSへ拡張したか説明する。}

\cite{Bleyer2011BMVC_PatchMatchStereo}は、基本的に2枚の画像（ステレオペア）間でのマッチングを前提としている。
しかし、実際のSfM/MVSパイプラインでは、数十から数千枚の画像（Multi-View）が入力され、かつそれらがインターネット上の写真のように撮影条件がバラバラな「非構造化（Unstructured）」データである場合もある。
\fix{このとき、画像間でのパッチ選択は非効率!?!?}
この課題に対し、\cite{Schonberger2016ECCV_PatchMatchStereo} は、PatchMatch Stereoのフレームワークを多視点へ拡張する際、「画素ごとの視点選択 (Pixelwise View Selection)」という概念を導入することで解決を図った。

多視点ステレオにおける最大の課題は、ある参照画像の画素 $\Gamma$ を復元するために、「どのソース画像を使うべきか」が画素ごとに異なる点である。
画像全体で一律にソース画像を選んでしまうと、オクルージョンや解像度の不一致により、特定の画素ではマッチングが破綻してしまう。
COLMAPでは、以下の3つの幾何学的事前分布 (Geometric Priors) を確率モデルに組み込み、各画素 $\Gamma$ が自分自身にとって最適なソース画像を動的に選択しながら推論を行う。

\begin{enumerate}
    \item \textbf{Triangulation Prior}: 
    十分なベースラインを持ち、三角測量の精度が保証される角度（Triangulation Angle）で撮影された画像を優先する。
    角度が小さすぎる（視点が近すぎる）画像は深度推定の不確定性が高いため除外される。
    
    \item \textbf{Resolution Prior}: 
    参照画像とソース画像で、対象を捉えている解像度（画素密度）が類似している画像を優先する。極端に解像度が異なる画像間でのマッチングは、エイリアシング等の問題を引き起こすためである。
    
    \item \textbf{Incident Prior}: 
    推定された法線ベクトルに対し、カメラ視線が正対に近い（斜めすぎない）画像を優先する。これにより、極端な浅い角度から撮影された信頼性の低い画像の影響を排除する。
\end{enumerate}

Schönbergerらは、これらの幾何学的尺度とフォトメトリックな整合性を統合した確率的グラフィカルモデルを構築し、PatchMatchの反復プロセスの中で「深度・法線の推定」と「最適なソース画像の選択」を同時に最適化する手法を確立した。
これにより、COLMAPは極めてノイズの多い非構造化データセットに対しても、Robustな密な三次元再構成を可能にした。

\fix{一方、Geometric Opticsによる光の直進性を仮定するが、これは屈折のあるSceneでは成立しない。(Reflectionも一般的に苦手)}




\subsection{Feed Forward 3D Reconstruction}
\checkref{\url{https://gemini.google.com/app/d37c008e08350238}}

\note{DINO などの深層学習ベースの特徴抽出を解説。自分の提案手法の前処理にも、水面マスクにDinoを使用する}

本研究の本筋である最適化ベース（Optimization-based）の手法とは対照的に、近年（2023-2025年）、大規模データセットとDeep Learning、特にTransformerアーキテクチャの発展により、幾何学的計算を推論（Inference）として解く「フィードフォワード型（Feed-Forward）」の手法が急速に台頭している。
従来の手法（SfM/MVSやNeRF/3DGS）が、入力シーンごとにパラメータを反復的に更新して解を探索するのに対し、フィードフォワード型の手法は、学習済みの膨大な事前知識（Priors）を用いて、単一の順伝播処理のみで3次元構造を回帰するデータ駆動型（Data-driven）のアプローチである。

このアプローチの代表例として、以下の手法が挙げられる。

\begin{itemize} 
  \item \textbf{Depth Anything} \cite{yang2024depthanything}: 6200万枚以上の画像から学習された基盤モデル（Foundation Model）であり、DINOv2\cite{}バックボーンを活用することで、テクスチャのない領域や未知のシーンに対しても極めてロバストな単眼深度推定を実現している。
  しかし、出力はスケール不確定性を伴う2.5次元表現に留まり、多視点間での厳密な幾何学的整合性は保証されない。
  
  \item \textbf{DUSt3R / MASt3R} \cite{wang2024dust3r, leroy2025mast3r}: 従来のSfMパイプライン（特徴点抽出、マッチング、バンドル調整）を完全に排除し、2枚の画像から直接「ポイントマップ（Point Map）」を回帰する手法である。
  これにより、カメラパラメータを事前に与えることなく（Unposed）、エンドツーエンドでの3次元形状およびPoint Mapからのカメラ姿勢の逆推定が可能となった。
  特にMASt3Rは、~。
  \checkref{MASt3R ってそんな手法だっけ?}
  
  \item \textbf{VGGT (Visual Geometry Grounded Transformer)} \cite{wang2025vggt}: CVPR 2025にてBest Paper Awardを受賞した、現時点での到達点といえる手法である。
  VGGTは、任意の枚数の画像を入力とし、カメラパラメータ、深度、点群、そして追跡情報（Tracks）の全てを同時に推論する。

\end{itemize}

これらの手法は、計算速度とロバスト性において革新的であるが、本研究が扱う「物理的に正確な表面再構成」の観点からは明確な限界も存在する。
フィードフォワード手法はその性質上、学習データに深く性能を依存する。

そのため、屈折（Refraction）や透明物体（Transparency）を含むシーンにおいて、これらの手法は破綻しやすい。
学習データ（ScanNet等）に透明物体が十分に、かつ物理的に正確なアノテーションと共に含まれていないため、フィードフォワードモデルはガラス表面を背景と混同したり、深度を平滑化してしまう傾向がある。
\fix{根拠薄し}
対して、本研究で用いるGaussian Splatting等の最適化ベース手法は、屈折率（IoR）やスネルの法則を明示的にモデル化することで、こうした物理現象を正確に逆算することが可能である。

しかし、動画生成AIが流体や光の反射といった物理法則をデータから獲得しつつある現状 \cite{quan2025transparent} を鑑みると、将来的にはフィードフォワード手法も十分なデータスケールによって屈折を「学習」する可能性は否定できない。
現時点では、幾何学的整合性と物理的忠実性を担保するためには、依然として物理モデルに基づく最適化が不可欠である。

\missingfigure{Optimization-based手法とFeed-Forward手法の処理フロー比較図：Iterativeなループを持つ前者と、Single Passで完結する後者の対比。また、透明物体に対する挙動の違い（透過してしまうか、屈折を考慮するか）の概念図。} 
