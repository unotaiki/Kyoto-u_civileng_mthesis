%!TEX root = ../main.tex
\chapter{背景理論}

\section{画像に基づく3次元復元 (3D Reconstruction from Images)}
画像を用いた測量は写真測量(Photogrammetry)と呼ばれ、古い歴史あり。
\url{https://duplicate-3d.com/rd/2025-09-11-photogrammetry-history/} この記事を参考に。
もともとは専門的な技能を持った人が、専用の機械(?)を用いて作成。

画像のデジタル化、イメージセンサの発明によりコンピュータビジョン（Computer Vision, CV）が始まる。
Image Sensorから得た視覚情報から、人間や他の生物と同じようにComputerやMachineにSceneを理解させる。

画像センサ（Image Sensor）が捉える情報は、本質的には3次元シーンから2次元平面への射影（Projection）である。
この過程において、3次元空間の奥行き情報は1次元分欠落し、情報の「縮退」が発生する。
3次元復元の主眼は、この失われた次元を幾何学的制約や事前知識（Priors）を用いて補完し、元のシーンの構造を逆問題として解くことにある。
3次元情報は生物が自己が生きる世界を認識、理解するうえで必須の情報であり、ロボットの自己位置推定、環境認識などにも多大なニーズがあり、Computer Visionの主要タスクとして数多くの研究がなされ、今もめちゃくちゃレッドオーシャン。

古くから、単眼画像から形状を推定する手法として、輝度やテクスチャ、影などの手掛かりを利用する \textit{Shape from X}（$X \in \{\text{shading, Silhouette, Texture, Focus, etc.}\}$）の研究が行われてきた。
しかし、より頑健な復元を行うためには、視点移動を伴う複数枚の画像、あるいは動画（Image sequence）を用いて幾何的な整合性を元に手法が主流となった。
この手法、タスクの総称を Structure from Motion (SfM) と呼ぶ。
このSfMを起点とする、3D Vision for Geometry手法の発達、高度なUIを備えた商用ソフト(Pix4D, Metashape, etc.)の出現、オープンソース化により、今日ではPhotogrammetry技術は広く一般に普及した。

\subsection{Structure from Motion}
SfMは、複数の視点から撮影された画像群に基づき、カメラの内部・外部パラメータ（三次元的な動き）と、シーンの疎な（Sparse）3次元構造を同時に推定する手法である。
Tomasi-Kanadeによる行列分解法に始まる。
HartleyやZissermanら(2000年代)によって幾何学的理論の基礎が確立された。 (VGGTのYoutubeの対談動画で取り上げられていた。もう少し詳しくは、Harley先生たちの本を参照。)
2016年に発表された COLMAP は、高い精度と汎用性、そしてOpen Sourceのプロジェクトとしての完成度から現在でもアカデミック分野でデファクトスタンダードとして広く利用されている。
\checkref{COLMAPでは、Pixel wiseなんちゃらで、MVSの新規研究も実装されている}
また、COLMAPにより出力される、正確なカメラ内部パラメータ(Intrinsic)と外部パラメータ(Extrinsic)は、歪みのない画像(Undistorted Images)は、後述するDense Reconstruction や 新規視点合成タスク のための入力データとして、重要なパイプラインの一角を担っている。

In a typical incremental SfM pipeline, keypoints are firstly detected and matched across frames using feature detectors and descriptors such as SIFT \parencite{Lowe2004_SIFT}.
Fundamental matrix $F$ between two images is then calculated, commonly via eight-points algorithm \parencite{Hartley1997_8PointAlgorithm} combined with random sample consensus (RANSAC) \parencite{Fischler1987_RANSAC}, which lead to camera pose recovery through singular value decomposition.
New camera poses are iteratively registered via Perspective-n-Point algorithms, which align estimated 3D points with 2D features in new frames.
Triangulation is subsequently applied to obtain additional 3D points from feature correspondences, and bundle adjustment (BA) \parencite{Triggs2000_BA} is finally performed to minimize reprojection error, refining both camera parameters and 3D points. 
画像を貼るぞい!!!http://theia-sfm.org/sfm.html

\begin{figure}[htbp]
  \centering
  \captionsetup{justification=raggedright}
  \includegraphics[width=0.7\linewidth]{figure/40_prelim/sfm_pipeline.png}
  \caption{SfM Pipeline \cite{fig:Theia-SfM}}
  \label{fig:sfm_pipeline}
\end{figure}

\subsection{Multi-View Stereo}
SfMなどによって得られたカメラパラメータが既知の多視点画像郡から、各画素単位で密な深度推定により、高密度な三次元復元を行うのが Multi-View Stereo (MVS) である。
SfMの出力三次元情報が疎な(Sparse)点群であるのに対して、MVSは物体表面の密な(Dense)な三次元点群やメッシュ(Mesh)を推定することから、MVSは Dense 3D Reconstruction (密な三次元再構成)のタスクを行っていると言える。
これを達成するため、各画素における深度(Depth)や法線(Normal)といった幾何パラメータを、画像間の整合性(Photometric Consistency)に基づいて最適化する手法がとられる。
本節では、パッチベース手法の古典であるPMVS \cite{Furukawa2010_PatchMVS} の概念を概観した後、現在のデファクトスタンダードなパイプライン（COLMAP \cite{Schnberger2016ECCV_PatchMatchStereo}）の基礎となっているPatchMatch Stereoについて詳述する。



% --- PMVS ---
\textbf{PMVS}: 

\subsubsection{Patch-based Multi-View Stereo (PMVS)}

\cite{Furukawa2010_PMVS} によって提案された Patch-based Multi-View Stereo (PMVS) は、物体表面を微小な平面パッチの集合としてモデル化し、これを拡張・最適化することで密な3次元形状を復元する手法である。
本手法は、特徴点マッチングによる疎な初期復元から出発し、信頼度の高いパッチを周囲に拡張(Expand)していくアプローチをとる、物体表面の形状を密に3次元推定するための先駆的かつ代表的な手法である。
\checkref{cite{}では、現在の設定では名前が表示されずただ、[8]のように番号のみになるため、別の方法や引用のフォーマットの設定を考える}

PMVSにおける基本単位であるパッチ $B$ は、単なる画像の矩形領域ではなく、対象物体の表面に接する微小平面（局所接平面）の近似として定義される。
パッチ $B$ は以下のパラメータを持つ。
\begin{itemize}
    \item \textbf{中心座標} $\bm{p_B} \in \mathbb{R}^3$: パッチの中心位置。
    \item \textbf{法線ベクトル} $\mathbf{n_B} \in \mathbb{R}^3$: パッチの向きを表す単位法線ベクトル。
    \item \textbf{参照画像} $R_B$: パッチ $B$ を観測する画像の中で、光学的・幾何的に最も適した画像。
    \item \textbf{可視画像集合} $V_B$: パッチ $B$ がオクルージョンなく観測可能であり、かつ相関スコアが閾値以上となる画像の集合。
\end{itemize}

PMVSの処理は、特徴点からの初期化(Initialization)の後、以下の3つのステップ、拡張(Expansion)、フィルタリング(Filtering)、最適化(Optimization)を反復することで行われる。

\begin{enumerate}
    \item \textbf{Initialization (初期化)}:
    SfMと同様に、各画像から特徴点検出･マッチングを行う\cite{Lowe2004_SIFT}。
    ここから得られる疎な点群をSeed Patchとして、初期の法線とともに最初のパッチ郡を生成するよ。
    前処理としてカメラパラメータの取得にSfMを用いている場合、これらの特徴点と、Triangulation(三角測量)によって得られる疎な三次元点群はそのまま使用できる。

    \item \textbf{Expansion (拡張)}:
    物体の表面が滑らかに連続しているという仮定に基づき、パッチをシーンの表面に沿うように増殖させていく。
    既存のパッチ $B$ を参照画像 $R_B$ および可視画像集合 $V_B$ に投影し、その隣接画素に対応する空間領域にパッチが存在しない場合、新たなパッチ $B'$ を生成する。
    この際、親パッチ $B$ の法線 $\mathbf{n_B}$ と深さ情報を初期値として継承させることで、テクスチャが弱い領域であっても、隣接する確度の高い領域から表面を「張り出して」いくことが可能となる。

    \item \textbf{Filtering (フィルタリング)}:
    拡張プロセスによって生じた誤ったパッチを除去する。以下の3つの基準が主に用いられる。
    \begin{itemize}
        \item \textbf{Visibility Consistency}: 複数のパッチが同一の視線上に存在する場合、カメラに近い方を残し、隠蔽される奥のパッチを削除する。
        \item \textbf{Photometric Consistency}: 正規化相互相関 (NCC) 等を用いた画像間の整合性スコアが一定以下のパッチを外れ値として破棄する。
        \item \textbf{Number of Views}: パッチを安定して観測できるカメラの台数 $|V(p)|$ が最小閾値未満のものを信頼性不足として削除する。
    \end{itemize}

    \item \textbf{Optimization (最適化)}:
    各パッチの位置 $\bm{p_B}$ と法線 $\mathbf{n_B}$ を微修正し、画像間の整合性を最大化する。
    具体的には、パッチ $B$ を可視画像 $I \in V_B$ へ投影して得られる画素値と、参照画像 $R_B$ 上の画素値との間のPhotometric Discrepancyを最小化するように、非線形最適化を行う。
    \begin{equation}
      g(p) = \frac{1}{|V(B) \setminus R(B) |} \sum_{I \in V(B), I \neq R(B)} \text{g}(B, I, R(B))
    \end{equation}
    ここで,$\text{g}(B, I_1, I_2)$は、パッチ$B$に対する、画像$I_1$と$I_2$の間のPhotometric Discrepancyを測定するための関数であり、NCCなどを使用することができる。
    \rewrite{Photometric Discrepancyを日本語で説明すると、}
    この際、パッチの法線 $\mathbf{n}(p)$ を考慮して各画像をホモグラフィ変換することで、視点による透視歪みを補正し、より正確なマッチングを実現している。
\end{enumerate}

以上のプロセスを収束するまで繰り返すことで、初期の疎な点群は徐々に密度を増し、最終的に物体表面全体を覆う密な点群が得られる。
\cite{Furukawa2010_PMVS} の手法は、大域的な最適化を行うPatchMatch Stereo等と比較して局所的な貪欲法に近い性質を持つが、拡張ステップによる表面の連続性利用が強力であり、密な復元を実現するための歴史的に重要な手法である。


% --- PatchMatch Stereo ---
\textbf{PatchMatch Stereo}: 
PMVSが「確信度の高い種（Seed）を育てていく」のに対し、PatchMatch Stereoは「ランダムな推測から始め、隣接画素の良い推測結果を伝播（Propagate）させて全体を収束させる」という、全く逆のアプローチを取る。

これは元々、画像編集（Inpainting）のためにBarnesらが2009年に提案したアルゴリズムを、Bleyerらが2011年にStereoに、そして\cite{Schnberger2016ECCV_PatchMatchStereo}が2016年にMVSへと拡張したよ。

\checkref{理解する。本当にそうか?あと、論文と}
参照画像上のすべての画素 $\Gamma$ に対して、局所的な接平面（Local Tangent Plane）を推定する.
\note{Local Tangent Planeとは? またLocal Tangent Plane仮説とはどういうPrior?}
単なる「深度 $d$」のスカラー値推定ではなく、「深度 $d$ + 法線 $\mathbf{n}$」を推定するのが最大の特徴です。
これにより、斜めの面（Slanted surface）に対しても高いフォトメトリック整合性を確保できます。
画素 $\Gamma$ における平面パラメータ $\theta_\Gamma$ は以下のように定義される: $\theta_\Gamma = \{ d_\Gamma, \mathbf{n}_\Gamma \}$。
ここで、$d_\Gamma$ は深さ、$\mathbf{n}_\Gamma$ は法線ベクトルです。
この平面仮説を用いると、カメラ内部行列$K$を用いて、参照画像の画素 $\Gamma$ をソース画像へ投影する際のホモグラフィ $H_\Gamma$ が誘導されます（Plane-induced Homography）。
\begin{equation}
H_\Gamma = \mathbf{K} \left( \mathbf{R} - \frac{\mathbf{t} \mathbf{n}_\Gamma^T}{d_\Gamma} \right) \mathbf{K}^{-1}
\end{equation}
\note{ソース画像とは何?}
この $H_\Gamma$ を用いてパッチを変形させることで、視点変更に伴うパースペクティブ歪みを考慮した正確なマッチングコスト計算が可能になる。

Initialization（ランダム初期化）: 全ての画素に対して、深度と法線を完全なランダム値で初期化する。

Propagation（伝播）:「空間的一貫性（Spatial Consistency）」**を利用します。「ある画素の正しい平面パラメータは、その隣接画素の平面パラメータと似ている可能性が高い」という仮定に基づき、隣接画素のパラメータを自分のものとしてテスト。
画像を左上から右下へ、次は右下から左上へと走査します。比較: 現在の画素 $\Gamma$ のコストと、隣接画素（例えば左 $p_l$ と上 $p_u$）のパラメータ $\theta_{pl}, \theta_{pu}$ を $p$ に適用した時のコストを比較します。更新: もし隣接画素のパラメータの方がコストが低ければ、そのパラメータを自分のものとして採用（コピー）します。これにより、画像の端にある「正解に近い値」が、反復ごとに画像全体へ波紋のように広がっていきます。Step 3: View Selection（ビュー選択）COLMAPの実装（Pixelwise View Selection for Unstructured Multi-View Stereo）において重要なのが、画素ごとに最適なソース画像を選択する点です。全画像を使うのではなく、その画素の法線やオクルージョンを考慮し、フォトメトリックに最も信頼できるソース画像群を動的に選び出し、スコアを計算します。これによりロバスト性が飛躍的に向上します。Step 4: Refinement（摂動と微調整）Propagationだけでは、既存の値をコピーするだけで、新たな値（Sub-pixel精度）が生まれません。そこで、現在のパラメータ $\theta_p$ に微小なランダムノイズ（摂動）を加え、コストが下がるなら更新します。反復が進むにつれてノイズの範囲（探索半径）を小さくしていくことで、局所解へ収束させます。


\textbf{PatchMatch Stereo}:
PMVSが、信頼度の高い特徴点からパッチを空間的に拡張(Expand)していく「局所的な成長法」であるのに対し、PatchMatch Stereoは、画像全体でランダムに初期化された幾何パラメータを、近傍画素間の空間的連続性を利用して伝播(Propagate)させ、大域的に最適化するアプローチをとる。
Barnesらによる画像補完アルゴリズムをステレオマッチングに応用したBleyerらの手法を発展させ、Schönbergerら \cite{Schnberger2016ECCV_PatchMatchStereo} は、非構造化画像群(Unstructured Images)に対してロバストな画素ごとの視点選択(Pixelwise View Selection)を組み込んだMVSアルゴリズムを提案した。

\subsubsection*{局所接平面近似と誘導ホモグラフィ}
従来のステレオマッチングでは、マッチングウィンドウをカメラに対して平行(Fronto-parallel)であると仮定することが多かった。しかし、この仮定は地面や壁などの斜めの面(Slanted Surface)において成立せず、マッチング精度を低下させる。
PatchMatch Stereoでは、参照画像上の画素 $l$ における幾何形状を、深度 $\theta_l$ と法線 $\mathbf{n}_l \in \mathbb{R}^3$ ($||\mathbf{n}_l||=1$) で定義される**局所接平面(Local Tangent Plane)**としてパラメータ化する [cite: 105]。

この平面仮説に基づき、参照画像(Reference)上のパッチをソース画像(Source) $m$ へ投影する変換は、以下の平面誘導ホモグラフィ(Plane-induced Homography) $H_l^m$ によって記述される [cite: 105]。
\begin{equation}
    H_l^m = \mathbf{K}^m \left( \mathbf{R}^m - \frac{\mathbf{t}^m \mathbf{n}_l^T}{d_l} \right) \mathbf{K}^{-1}
\end{equation}
ここで、$\mathbf{K}, \mathbf{K}^m$ はそれぞれ参照・ソースカメラの内部パラメータ行列、$\mathbf{R}^m, \mathbf{t}^m$ は参照カメラからソースカメラへの相対回転および並進ベクトル、$d_l$ は平面までの垂直距離である。
この $H_l^m$ を用いてパッチを変形させることで、視点変化に伴う透視投影歪みを考慮した、高精度なPhotometric Consistencyの評価が可能となる [cite: 110]。

\subsubsection*{推論アルゴリズム}
PatchMatch MVSは、以下のステップを反復することで、各画素の深度 $\theta_l$ と法線 $\mathbf{n}_l$ を推定する。

\begin{enumerate}
    \item \textbf{Initialization (初期化)}:
    各画素に対し、深度と法線をランダムな値で初期化する。あるいは、SfMで得られた疎な点群が存在する場合、それを初期値として利用することで収束を早めることが可能である [cite: 108]。

    \item \textbf{Propagation (伝播)}:
    「隣接する画素は、同じ3次元平面上に位置する可能性が高い」という空間的一貫性(Spatial Consistency)を利用する。
    画像上をスキャン（例：左上から右下へ）し、現在の画素 $l$ のパラメータと、隣接画素（例：左および上）のパラメータを用いてマッチングコストを計算・比較する。もし隣接画素のパラメータを用いた方がコストが低ければ、現在の画素の値を隣接画素の値で更新する。この処理により、画像の局所的な領域で正しい推定値が得られれば、それが波及的に全体へ伝播していく [cite: 117]。
    Schönbergerらの手法では、単にパラメータをコピーするだけでなく、法線情報を用いて隣接画素の平面を現在の画素位置まで延長し、その交点の深度を候補とする幾何学的な伝播を行うことで、曲面への追従性を向上させている [cite: 117]。

    \item \textbf{View Selection (視点選択)}:
    非構造化データセットでは、ある画素にとって最適なソース画像が、隣接画素にとっても最適とは限らない（オクルージョン等のため）。
    Schönbergerら \cite{Schnberger2016ECCV_PatchMatchStereo} は、以下の幾何学的な事前分布(Geometric Priors)を導入し、画素ごとに最適なソース画像を確率的に選択する [cite: 7, 169]。
    \begin{itemize}
        \item \textbf{Triangulation Prior}: ベースラインが短すぎない（三角測量の精度が確保できる）画像を優先する [cite: 171]。
        \item \textbf{Resolution Prior}: 参照画像と解像度（画素密度）が近い画像を優先する [cite: 182]。
        \item \textbf{Incident Prior}: 推定された法線に対し、正対に近い角度で撮影されている画像を優先する [cite: 192]。
    \end{itemize}
    これらの事前分布と、現在の幾何推定値に基づくPhotometric Consistencyを統合した確率モデル（Generalized EMアルゴリズム）を用いることで、ロバストな推定を実現している [cite: 202]。

    \item \textbf{Refinement (微調整)}:
    伝播ステップだけではパラメータの離散的なコピーしか行われないため、Sub-pixel精度の推定を行うために、現在のパラメータ $\theta_l, \mathbf{n}_l$ に微小なランダム摂動(Perturbation)を加えてテストし、コストが改善すれば更新する [cite: 126]。
\end{enumerate}

以上のプロセスを経ることで、初期のランダムな状態から、幾何学的・光学的に整合性の取れた密な深度・法線マップが得られる。


\subsection{Feed Forward 3D Reconstruction}
\note{本筋とは直接繋がらないから、、消すかどうか?}
近年（2023-2025年現在、大規模データセットを用いた深層学習、特に Transformer アーキテクチャの導入により、従来の幾何学的手法を代替・補完する「フィードフォワード型」の手法が急速に台頭している。
従来手法が、Optimization-basedの手法であるのに対し、Feed Forwardの手法は、Data-drivenの手法である。

Depth Anything\cite{}: 膨大な画像データから学習された 3D Priors を活用することで、未知のシーンに対しても極めて精緻な単眼深度推定を実現している。

DUSt3R / MASt3R\cite{}: 従来の SfM/MVS のような複雑なパイプライン（特徴点抽出、マッチング、 bundle adjustment 等）を介さず、2枚の画像から直接 Point Map を回帰する。これにより、カメラパラメータを事前に与えることなく、エンドツーエンドでの3次元形状およびカメラ姿勢の推定が可能となった。

VGGT\cite{}: Best Paper Award at CVPR 2025.

現在、大規模モデルによるデータ駆動型のアプローチへと大きなパラダイムシフトを迎えている。

SfM、MVSなどはGeometric Opticsを前提とし、光線が直進するという普遍的で強い過程を前提に構築されており、
Feed Forward手法は、屈折のあるSceneが学習データには不足しており、屈折のあるSceneを正確な一貫性を持って復元できるかは疑問だ? 
(動画生成AIが流体や重力、光の反射といった物理法則を理解しつつある側面を考えると、いずれは屈折のあるSceneも学習データに含まれるようになるかもしれない。)

\missingfigure{Feed Forwardを表す図。と思ったが、これは本筋とほとんど関係ないんだよね}
