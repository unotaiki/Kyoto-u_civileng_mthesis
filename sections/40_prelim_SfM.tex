%!TEX root = ../main.tex
\chapter{背景理論}\label{chap:prelim_3d-reconstruction-from-images}

\section{画像に基づく3次元復元 (3D Reconstruction from Images)}\label{sec:prelim_3d-reconstruction-from-images}
画像を用いた測量は写真測量（Photogrammetry）と呼ばれ、19世紀半ばに航空写真測量の技術として確立されて以来、長い歴史を持つ。
初期の写真測量は、専門的な技能を持つ技術者が専用の測量機器を用いて手動で行うものであったが、画像のデジタル化とイメージセンサの発明により、コンピュータビジョン（Computer Vision, CV）の分野として発展した。
コンピュータビジョンは、画像センサから得られた視覚情報を処理し、人間や他の生物と同様に、コンピュータや機械がシーンを理解することを目指す学問分野である。

画像センサ（Image Sensor）が捉える情報は、本質的には3次元シーンから2次元平面への射影（Projection）である。
この過程において、3次元空間の奥行き情報は1次元分欠落し、情報の「縮退」が発生する。
3次元復元の主眼は、この失われた次元を幾何学的制約や事前知識（Priors）を用いて補完し、元のシーンの構造を逆問題として解くことにある。
3次元情報は、生物が自己が生きる世界を認識・理解するうえで必須の情報であり、ロボットの自己位置推定（SLAM: Simultaneous Localization and Mapping）や環境認識などにも多大なニーズがある。
そのため、Computer Visionの主要タスクとして数多くの研究が行われており、非常に活発な研究領域である。

古くから、単眼画像から形状を推定する手法として、輝度やテクスチャ、影などの手掛かりを利用する \textit{Shape from X}（$X \in \{\text{shading, Silhouette, Texture, Focus, etc.}\}$）の研究が行われてきた。
しかし、より頑健な復元を行うためには、視点移動を伴う複数枚の画像、あるいは動画（Image sequence）を用いて幾何的な整合性を元に手法が主流となった。
この手法、タスクの総称を Structure from Motion (SfM) と呼ぶ。
このSfMを起点とする、3D Vision for Geometry手法の発達、高度なUIを備えた商用ソフト(Pix4D, Metashape, etc.)の出現、オープンソース化により、今日ではPhotogrammetry技術は広く一般に普及した。

\subsection{Structure from Motion}
\kobayashi{項目のタイトルが英語と日本語が混在。日本語がある場合はなるべくした方がよいか}
Structure from Motion (SfM)は、複数の視点から撮影された画像群に基づき、カメラの内部パラメータ（Intrinsic Parameters）・外部パラメータ（Extrinsic Parameters、すなわちカメラの三次元的な位置と姿勢）と、シーンの疎な（Sparse）3次元構造を同時に推定する手法である。
SfMの理論的基礎は、Tomasi-Kanadeによる行列分解法\cite{Tomasi1992_FactorizationMethod}に始まり、HartleyとZissermanによって多視点幾何学（Multiple View Geometry）の理論体系\cite{Hartley2004_MultipleViewGeometry}として確立された。
2016年に発表されたCOLMAP \cite{schoenberger2016_colmap}は、高い精度と汎用性、そしてオープンソースプロジェクトとしての完成度から、現在でもアカデミック分野におけるデファクトスタンダードとして広く利用されている。
COLMAPにより出力される正確なカメラ内部パラメータと外部パラメータ、および歪み補正済み画像（Undistorted Images）は、後述する密な三次元再構成（Dense Reconstruction）や新規視点合成（Novel View Synthesis）タスクのための入力データとして、重要なパイプラインの一角を担っている。

一般的なインクリメンタルSfMパイプラインでは、まずSIFTなどの特徴量検出器および記述子\parencite{Lowe2004_SIFT}を用いて、画像間でキーポイント（特徴点）の検出およびマッチングを行う。
その後、2画像間の基本行列$F$を、8点アルゴリズム\parencite{Hartley1997_8PointAlgorithm}およびRANSAC\parencite{Fischler1987_RANSAC}を組み合わせて推定し、特異値分解（SVD）によるカメラ姿勢の復元へと繋げる。
新たなカメラ姿勢は、Perspective-n-Point（PnP）アルゴリズムにより、既に推定された3次元点と新規画像内の2次元特徴点との対応付きで逐次的に登録する。
対応点情報から三角測量（Triangulation）によって追加の3次元点群を求め、最後にバンドル調整（Bundle Adjustment, BA）\parencite{Triggs2000_BA}によって再投影誤差を最小化することで、カメラパラメータおよび3次元点群の両者を同時に高精度に最適化する。

\begin{figure}[htbp]
  \centering
  \captionsetup{justification=raggedright}
  \includegraphics[width=0.7\linewidth]{figure/40_prelim/sfm_pipeline.png}
  \caption{SfM Pipeline \cite{fig:Theia-SfM}}
  \label{fig:sfm_pipeline}
\end{figure}

\subsection{Multi-View Stereo}
\note{無駄に力入れて書きすぎ。MVSとかほとんど本題じゃない。むしろSfMを頑張って記述するべきだった。(いい勉強になったが)、Appendixに回した方がいいげ}
SfMなどによって得られたカメラパラメータが既知の多視点画像群から、各画素単位で密な深度推定により、高密度な三次元復元を行うのが Multi-View Stereo (MVS) である。
SfMの出力三次元情報が疎な(Sparse)点群であるのに対して、MVSは物体表面の密な(Dense)な三次元点群やメッシュ(Mesh)を推定することから、MVSは Dense 3D Reconstruction (密な三次元再構成)のタスクを行っていると言える。
これを達成するため、各画素における深度(Depth)や法線(Normal)といった幾何パラメータを、画像間の整合性(Photometric Consistency)に基づいて最適化する手法がとられる。
本節では、パッチベース手法の古典であるPMVS \cite{Furukawa2010_PatchMVS}の概念を概観した後、現在のデファクトスタンダードなパイプライン（COLMAP \cite{Schonberger2016ECCV_PatchMatchStereo}）の基礎となっているPatchMatch Stereoについて詳述する。

\subsubsection{Patch-based Multi-View Stereo (PMVS)}

\begin{figure}[htbp]
  \centering
  \captionsetup{justification=raggedright}
  \includegraphics[width=0.8\linewidth]{figure/40_prelim/PMVS.png}
  \caption{PMVS Pipeline。 \cite{fig:Theia-SfM}から引用。 
  左から右にかけてそれぞれの画像は、(1) 入力された多視点画像の一例; (2) 検出された特徴点; (3) 初期マッチング後のパッチ; (4) 拡張とフィルタリング後のパッチ; (5) メッシュモデル.}
  \label{fig:pmvs_pipeline}
\end{figure}

\cite{Furukawa2010_PMVS} によって提案された Patch-based Multi-View Stereo (PMVS) は、物体表面を微小な平面パッチの集合としてモデル化し、これを拡張・最適化することで密な3次元形状を復元する手法である。
本手法は、特徴点マッチングによる疎な初期復元から出発し、信頼度の高いパッチを周囲に拡張(Expand)していくアプローチをとる、物体表面の形状を密に3次元推定するための先駆的かつ代表的な手法である。
\checkref{cite{}では、現在の設定では名前が表示されずただ、[8]のように番号のみになるため、別の方法や引用のフォーマットの設定を考える}

PMVSにおける基本単位であるパッチ $B$ は、単なる画像の矩形領域ではなく、対象物体の表面に接する微小平面（局所接平面）の近似として定義される。
パッチ $B$ は以下のパラメータを持つ。
\begin{itemize}
    \item \textbf{中心座標} $\bm{p_B} \in \mathbb{R}^3$: パッチの中心位置。
    \item \textbf{法線ベクトル} $\mathbf{n_B} \in \mathbb{R}^3$: パッチの向きを表す単位法線ベクトル。
    \item \textbf{参照画像} $R_B$: パッチ $B$ を観測する画像の中で、光学的・幾何的に最も適した画像。
    \item \textbf{可視画像集合} $V_B$: パッチ $B$ がオクルージョンなく観測可能であり、かつ相関スコアが閾値以上となる画像の集合。
\end{itemize}

PMVSの処理は、特徴点からの初期化(Initialization)の後、以下の3つのステップ、拡張(Expansion)、フィルタリング(Filtering)、最適化(Optimization)を反復することで行われる。

\begin{enumerate}
    \item \textbf{Initialization (初期化)}:
    SfMと同様に、各画像から特徴点検出・マッチングを行う\cite{Lowe2004_SIFT}。
    ここから得られる疎な点群をSeed Patchとして、初期の法線とともに最初のパッチ群を生成する。
    前処理としてカメラパラメータの取得にSfMを用いている場合、これらの特徴点と、三角測量（Triangulation）によって得られる疎な三次元点群はそのまま使用できる。

    \item \textbf{Expansion (拡張)}:
    物体の表面が滑らかに連続しているという仮定に基づき、パッチをシーンの表面に沿うように増殖させていく。
    既存のパッチ $B$ を参照画像 $R_B$ および可視画像集合 $V_B$ に投影し、その隣接画素に対応する空間領域にパッチが存在しない場合、新たなパッチ $B'$ を生成する。
    この際、親パッチ $B$ の法線 $\mathbf{n_B}$ と深さ情報を初期値として継承させることで、テクスチャが弱い領域であっても、隣接する確度の高い領域から表面を「張り出して」いくことが可能となる。

    \item \textbf{Filtering (フィルタリング)}:
    拡張プロセスによって生じた誤ったパッチを除去する。以下の3つの基準が主に用いられる。
    \begin{itemize}
        \item \textbf{Visibility Consistency}: 複数のパッチが同一の視線上に存在する場合、カメラに近い方を残し、隠蔽される奥のパッチを削除する。
        \item \textbf{Photometric Consistency}: 正規化相互相関 (NCC) 等を用いた画像間の整合性スコアが一定以下のパッチを外れ値として破棄する。
        \item \textbf{Number of Views}: パッチを安定して観測できるカメラの台数 $|V(p)|$ が最小閾値未満のものを信頼性不足として削除する。
    \end{itemize}

    \item \textbf{Optimization (最適化)}:
    各パッチの位置 $\bm{p_B}$ と法線 $\mathbf{n_B}$ を微修正し、画像間の整合性を最大化する。
    具体的には、パッチ $B$ を可視画像 $I \in V_B$ へ投影して得られる画素値と、参照画像 $R_B$ 上の画素値との間のPhotometric Discrepancyを最小化するように、非線形最適化を行う。
    \begin{equation}
      g(p) = \frac{1}{|V(B) \setminus R(B) |} \sum_{I \in V(B), I \neq R(B)} \text{g}(B, I, R(B))
    \end{equation}
    ここで、$\text{g}(B, I_1, I_2)$は、パッチ$B$に対する、画像$I_1$と$I_2$の間のフォトメトリック不一致度（Photometric Discrepancy）を測定するための関数であり、正規化相互相関（NCC）などを使用することができる。
    フォトメトリック不一致度は、同一の3次元パッチを異なる視点から観測した際の画素値の差異を定量化する指標である。
    この際、パッチの法線 $\mathbf{n}(p)$ を考慮して各画像をホモグラフィ変換することで、視点による透視歪みを補正し、より正確なマッチングを実現している。
\end{enumerate}

以上のプロセスを収束するまで繰り返すことで、初期の疎な点群は徐々に密度を増し、最終的に物体表面全体を覆う密な点群が得られる。
\cite{Furukawa2010_PMVS} の手法は、大域的な最適化を行うPatchMatch Stereo等と比較して局所的な貪欲法に近い性質を持ち、計算コストが高いが、拡張ステップによる表面の連続性利用が強力であり、密な復元を実現するための歴史的に重要な手法である。


% --- PatchMatch Stereo ---
\subsection{PatchMatch Stereo}

PMVSが、信頼できる「種（Seed）」から局所的に表面を拡張していくアプローチであるのに対し、\cite{Bleyer2011BMVC_PatchMatchStereo} が提案した PatchMatch Stereo は、画像上のすべての画素に対して、個別の3次元平面パラメータ（深度と法線）を推定する手法である。

従来の局所ステレオマッチング手法は、マッチングウィンドウ内の深度が一定である（カメラに対して平行な平面：Fronto-parallel window）と仮定することが一般的であった。
しかし、この仮定は傾いた面や曲面において成立せず、再構成精度の低下や「階段状」のアーティファクトを生む原因となっていた。
これに対し、Bleyerらは各画素のウィンドウを3次元空間内の傾いた平面（Slanted Support Window）としてモデル化した。
しかし、各画素に対して最適な平面パラメータ（深度および法線の向き）を決定しようとすると、その探索空間は連続値であり無限大となるため、従来の総当たり的な探索や離散ラベルを用いる手法（Graph Cutsなど）は適用できない。

この問題を解決するために導入されたのが、Barnesらによる最近傍探索アルゴリズム "PatchMatch"の概念をステレオ視に応用した推論フレームワークである。

\textbf{平面モデルとマッチングコスト}:
左画像の各画素 $\Gamma$ に対し、3次元平面 $f_\Gamma$ を割り当てる。
平面 $f_\Gamma$ は3つのパラメータ $(a_{f_\Gamma}, b_{f_\Gamma}, c_{f_\Gamma})$ を持ち、画素 $\Gamma$ の座標 $(\Gamma_x, \Gamma_y)$ における深度 $d_\Gamma$ は以下の式で表される。
\begin{equation}
    d_\Gamma = a_{f_\Gamma} \Gamma_x + b_{f_\Gamma} \Gamma_y + c_{f_\Gamma}
\end{equation}
このモデルにより、画素ごとに異なる法線を持つ傾いた平面を表現でき、サブピクセル精度の深度推定が可能となる。
最適化の目的は、各画素 $\Gamma$ において、アグリゲーションコスト $m(\Gamma, f_\Gamma)$ を最小化する平面 $f_\Gamma$ を、無限の候補空間 $\mathcal{F}$ から見つけ出すことである。
\begin{equation}
    f_\Gamma = \operatorname*{argmin}_{f \in \mathcal{F}} m(\Gamma, f_\Gamma)
\end{equation}

\textbf{ランダム探索と伝播による推論}: 
PatchMatch Stereoの核心は、ランダムな初期化状態から、空間的・視点的な相関を利用して「良い解」を画像全体に伝播(Propagate)させるプロセスにある。
アルゴリズムは、以下のステップを反復することで収束する。

\begin{enumerate}
    \item \textbf{Random Initialization (ランダム初期化)}:
    初期状態では、すべての画素に対し、ランダムなパラメータを持つ平面（ランダムな深度と法線ベクトル）を割り当てる。

    \item \textbf{Spatial Propagation (空間伝播)}:
    「隣接する画素は、同じ平面上に乗っている可能性が高い」という仮定を利用する。
    画像走査順序に従い、現在の画素 $\Gamma$ とその近傍画素 $\Gamma'$（例えば左上の画素）を比較する。
    もし、近傍画素 $\Gamma'$ の持つ平面 $f_{\Gamma'}$ を画素 $\Gamma$ に適用した際のマッチングコストが、現在の平面 $f_\Gamma$ よりも低くなるならば、画素 $\Gamma$ は平面 $f_{\Gamma'}$ を自身の新たな推定値として採用し、コピーする。
    これにより、画像の一部で偶然「正解に近い平面」が見つかれば、その平面情報は波紋のように隣接画素へと広がり、領域全体が正しい平面で埋め尽くされていく。

    \item \textbf{View Propagation (視点間伝播)}:
    ステレオ特有の拡張として、左右画像間の一貫性を利用する。
    左画像の画素 $\Gamma$ の対応点である右画像の画素 $\Gamma'$ が、より適切な平面パラメータを持っている場合、それを左画像座標系へ変換して取り込む。これにより、オクルージョン領域外での整合性が強力に担保される。

    \item \textbf{Plane Refinement (平面の微調整)}:
    伝播のみでは、既存の平面パラメータのコピーしか行われないため、真値へ到達できない。そこで、現在の平面パラメータに微小なランダム摂動（Perturbation）を加え、コストが改善するかをテストする。反復が進むにつれて摂動の範囲を指数関数的に狭めていくことで、サブピクセルレベルでの高精度な収束を実現する。
\end{enumerate}


この手法の利点は、巨大なコストボリューム（Cost Volume）をメモリ上に構築する必要がないため、高解像度画像や大きな視差範囲に対してもメモリ効率が良い点にある。
また、連続空間での最適化を行うため、離散化に伴う量子化誤差が発生せず、極めて滑らかな曲面や急峻な傾斜面の復元に成功している。

\cite{Bleyer2011BMVC_PatchMatchStereo}は、基本的に2枚の画像（ステレオペア）間でのマッチングを前提としている。
しかし、実際のSfM/MVSパイプラインでは、数十から数千枚の画像（Multi-View）が入力され、かつそれらがインターネット上の写真のように撮影条件がバラバラな「非構造化（Unstructured）」データである場合もある。
この課題に対し、\cite{Schonberger2016ECCV_PatchMatchStereo}は、PatchMatch Stereoのフレームワークを多視点へ拡張する際、「画素ごとの視点選択（Pixelwise View Selection）」という概念を導入することで解決を図った。

多視点ステレオにおける最大の課題は、ある参照画像の画素 $\Gamma$ を復元するために、「どのソース画像を使うべきか」が画素ごとに異なる点である。
画像全体で一律にソース画像を選んでしまうと、オクルージョンや解像度の不一致により、特定の画素ではマッチングが破綻してしまう。
COLMAPでは、以下の3つの幾何学的事前分布 (Geometric Priors) を確率モデルに組み込み、各画素 $\Gamma$ が自分自身にとって最適なソース画像を動的に選択しながら推論を行う。

\begin{enumerate}
    \item \textbf{Triangulation Prior}: 
    十分なベースラインを持ち、三角測量の精度が保証される角度（Triangulation Angle）で撮影された画像を優先する。
    角度が小さすぎる（視点が近すぎる）画像は深度推定の不確定性が高いため除外される。
    
    \item \textbf{Resolution Prior}: 
    参照画像とソース画像で、対象を捉えている解像度（画素密度）が類似している画像を優先する。極端に解像度が異なる画像間でのマッチングは、エイリアシング等の問題を引き起こすためである。
    
    \item \textbf{Incident Prior}: 
    推定された法線ベクトルに対し、カメラ視線が正対に近い（斜めすぎない）画像を優先する。これにより、極端な浅い角度から撮影された信頼性の低い画像の影響を排除する。
\end{enumerate}

Schönbergerらは、これらの幾何学的尺度とフォトメトリックな整合性を統合した確率的グラフィカルモデルを構築し、PatchMatchの反復プロセスの中で「深度・法線の推定」と「最適なソース画像の選択」を同時に最適化する手法を確立した。
これにより、COLMAPは極めてノイズの多い非構造化データセットに対しても、ロバストな密な三次元再構成を可能にした。

一方、これらの手法は幾何光学（Geometric Optics）による光の直進性を仮定しているが、これは屈折のあるシーンでは成立しない。
また、反射（Reflection）を含むシーンにおいても、従来の手法は一般的に困難を抱えている。




\subsection{Feed Forward 3D Reconstruction}

本研究の本筋である最適化ベース（Optimization-based）の手法とは対照的に、近年（2023-2025年）、大規模データセットとDeep Learning、特にTransformerアーキテクチャの発展により、幾何学的計算を推論（Inference）として解く「フィードフォワード型（Feed-Forward）」の手法が急速に台頭している。
従来の手法（SfM/MVSやNeRF/3DGS）が、入力シーンごとにパラメータを反復的に更新して解を探索するのに対し、フィードフォワード型の手法は、学習済みの膨大な事前知識（Priors）を用いて、単一の順伝播処理のみで3次元構造を回帰するデータ駆動型（Data-driven）のアプローチである。

このアプローチの代表例として、以下の手法が挙げられる。

\begin{itemize} 
  \item \textbf{Depth Anything} \cite{yang2024depthanything}: 6200万枚以上の画像から学習された基盤モデル（Foundation Model）であり、DINOv2バックボーンを活用することで、テクスチャのない領域や未知のシーンに対しても極めてロバストな単眼深度推定を実現している。
  しかし、出力はスケール不確定性を伴う2.5次元表現に留まり、多視点間での厳密な幾何学的整合性は保証されない。
  
  \item \textbf{DUSt3R / MASt3R} \cite{wang2024dust3r, leroy2025mast3r}: 従来のSfMパイプライン（特徴点抽出、マッチング、バンドル調整）を完全に排除し、2枚の画像から直接「ポイントマップ（Point Map）」を回帰する手法である。
  これにより、カメラパラメータを事前に与えることなく（Unposed）、エンドツーエンドでの3次元形状およびPoint Mapからのカメラ姿勢の逆推定が可能となった。
  
  \item \textbf{VGGT (Visual Geometry Grounded Transformer)} \cite{wang2025vggt}: CVPR 2025にてBest Paper Awardを受賞した、現時点での到達点といえる手法である。
  VGGTは、任意の枚数の画像を入力とし、カメラパラメータ、深度、点群、そして追跡情報（Tracks）の全てを同時に推論する。

\end{itemize}

これらの手法は、計算速度とロバスト性において革新的であるが、本研究が扱う「物理的に正確な表面再構成」の観点からは明確な限界も存在する。
フィードフォワード手法はその性質上、学習データに深く性能を依存する。

そのため、屈折（Refraction）や透明物体（Transparency）を含むシーンにおいて、これらの手法は破綻しやすい。
一般的な学習データセット（ScanNet等）には透明物体が十分に、かつ物理的に正確なアノテーションと共に含まれていないため、フィードフォワードモデルはガラス表面を背景と混同したり、深度を平滑化してしまう傾向がある。
対して、本研究で用いるGaussian Splatting等の最適化ベース手法は、屈折率（Index of Refraction: IoR）やスネルの法則を明示的にモデル化することで、こうした物理現象を正確に逆算することが可能である。

しかし、動画生成AIが流体や光の反射といった物理法則をデータから獲得しつつある現状 \cite{quan2025transparent}を鑑みると、将来的にはフィードフォワード手法も十分なデータスケールによって屈折を「学習」する可能性は否定できない。
現時点では、幾何学的整合性と物理的忠実性を担保するためには、依然として物理モデルに基づく最適化が不可欠である。 
