\section{Literature Review}\label{RELATED}
\sloppy

Bathymetry in shallow water area has been explored through a variety of methodologies \parencite{He2024_survey-shallow-bathymetry}.
Traditional fields measurements methods with bathymetric rods or hammers, and global positioning systems (GPS) are extremely time-consuming and dangerous.
Shipborne sonar systems are a representative method of bathymetry, however, the operation is restricted due to its narrow scanning swath. % 引用をつける
Therefore, remote sensing that reconstructs underwater morphology from data observed in the air is valuable in this field.
As remote sensing for shallow bathymetry, platforms equipped with sensors are generally classified into satellite, airborne, and, UAV-based systems.
The sensors employed range from RGB cameras and multi/hyper-spectral cameras, to LiDAR and even Synthetic Aperture Radar (SAR).
As an efficient, inexpensive, safe, and accessible solution, Our work focuses on methods based on UAV-based RGB imagery.
% radiometric な手法に関して言及すべき?

To reconstruct 3D information from UAV imagery, previous works have employed geometric approaches such as Structure-from-Motion (SfM) \parencite{schoenberger2016_colmap} or Multi-View-Stereo (MVS) \parencite{Furukawa2010_PatchMVS,Furukawa2015_MVS},
which have been developed in the computer vision community.
In a typical incremental SfM pipeline, keypoints are firstly detected and matched across frames using feature detectors and descriptors such as SIFT \parencite{Lowe2004_SIFT}.
Fundamental matrix $F$ between two images is then calculated, commonly via eight-points algorithm \parencite{Hartley1997_8PointAlgorithm} combined with random sample consensus (RANSAC) \parencite{Fischler1987_RANSAC}, which lead to camera pose recovery through singular value decomposition.
New camera poses are iteratively registered via Perspective-n-Point algorithms, which align estimated 3D points with 2D features in new frames.
Triangulation is subsequently applied to obtain additional 3D points from feature correspondences, and bundle adjustment (BA) \parencite{Triggs2000_BA} is finally performed to minimize reprojection error, refining both camera parameters and 3D points. 
MVS builds upon the calibrated cameras estimated from SfM, computing dense per-pixel depth and normal maps across views, which are then fused into a dense 3D point cloud or mesh.

This entire pipeline assumes straight-line traveling of light, while in reality, refraction at water-air interface significantly degrades both SfM and MVS reconstructions.
This refractive distortion represents the key challenge in photogrammetric bathymetry. 
% Previous studies (and also our method) have attempted to address this issue under simplifying assumptions, such as high water clarity, minimal surface waves, calm water conditions, and textured visible beds.
\cite{Woodget2014_PhotograBathy-multiply-n} demonstrated the potential of photogrammetric bathymetry from UAV imagery, applying a simple refraction correction by multiplying refractive index to SfM software outputs.
\cite{Dietrich2016_multi-angle-correction} proposed multi-angle refraction correction based on the pixel ray angle and estimating 3D points, which consider the view-angle dependence of each apparent points. 
However, this method only corrects for vertical displacement, ignoring horizontal distortions.
\cite{Makris2024_refractive-aware-sfm} successfully integrated refraction modeling directly into the SfM pipeline, avoiding post-hoc or iterative correction. 
This R-SfM method enables highly accurate camera pose estimation and point clouds generation.
They combine Deep Learning method \parencite{Alevizos2022_DL-shallow-bathymetry} to compensate the sparseness of SfM output, however, Deep Learning based method needs extensive training datasets and remain highly site-dependent.















% \subsection{Bathymetry in shallow water}\label{BATHYMETRY-SHALLOW}



% \begin{itemize}
%   \item 船。コントロール難しい。ラジコンだと非効率
%   \item 人。論外
%   \item ALB。いい感じやけど高い。
%   \item マルチスペクトル。今、勉強
% \end{itemize}

% \subsection{Photogrammetric Bathymetry}\label{PHOTOGRAMETRIC-BATHYMETRY}
% 歴史は古いよ。\par
% まず、SfM、MVSパイプラインの結果に屈折率をかけたりしたよ。\par
% カメラとの位置関係などを考慮して補正する量を決めたよ。\par
% 画像自体を処理していく考え方が生まれたよ。\par
% 鶏と玉子の関係からイテラティブな処理になったよ。\par
% Refraction-Aware SfMでは、パイプラインに明示的に屈折を組み込んだよ。(自分もその問題に取り組んでいたよ)\par
% 多分だけど、Appearance Depthを用いていないから、光線状の交点を求める必要があってバンドル調整できないのかな?\par
% Machine Learningを使用する方法も提案されているよ。\par
% 明示的に、end-to-endで、屈折のないシーンを推定できて、出力が密だったら嬉しいよ。\par

% \subsection{Radiance Field}\label{RADIANCE-FIELD}
% NeRFに始まる、Photometricな3D Reconstructionだよ。\par
% 画像から、幾何的な情報ではなくPhotometricな情報と3Dモデルのレンダリングを一致させるように最適化するよ。\par

% SonarベースのBathymetric Surveyが難しいShallow Water Areaにおいて、様々な手法が提案されている。
% (Survey論文を参考に)
% Satellite Image と UAV画像とを比較すると、UAVの方が個人や研究室単位で、頻度高く、自由度を持って、かつ解像度を上げたデータ取得が可能である。
% 水中での光スペクトルの減衰率を基にしたRadiometricな手法とGeometricな手法がある。
% 測量という観点から、
