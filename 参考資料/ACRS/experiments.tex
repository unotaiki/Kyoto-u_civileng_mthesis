\section{Experiments}\label{sec:EXPERIMENTS}

\subsection{Dataset}\label{sec:dataset}

\begin{wrapfigure}{r}{0.45\linewidth}
  \includegraphics[width=\linewidth]{figure/experiment/simulator.png}
  \caption{Overview of our simulated data capture setup.}\label{fig:simulator-settings}
\end{wrapfigure}

% 本研究では、屈折の影響に焦点を当てているため、他の水面での反射や水中での光の減衰の影響を除外するためシミュレーションベースの県境を行う。
% 実際の環境では水中での光の減衰や反射、波の影響を無視できないため、これらは本研究のLimitationとなる。
% まず、Blenderで、川底をイメージした礫のテクスチャを用意し、Displacementモディファイアを用いてることで、詳細な地形の凹凸を表現したメッシューデタを作成する。
% このデータセットは、パストレーシングレンダラーであるBlender Cyclesによって物理的正確なレンダリング画像を生成する。
% 屈折面は歪みのない平面を仮定する。
% 平均的な深度は10mに設定した。
% 撮影は、河床を中心に、85\%ずつのサイドラップ率とオーバーラップ率で撮影を行い、さらに、ナディア各20°、40°で河床中心を、Circle Aroundするように撮影した画像を取得する。
% これらの条件は多視点性をもたらし、Gaussian Splattingをはじめとする多視点Geometry推定に有利な条件となるが、\cref{fig:space_compression_by_view}のように、屈折面への観測角が大きくなるほど物体の歪みや見かけの位置と真値の差も大きくなることから、屈折の影響の排除も難しくなる。
% 一方、実条件での撮影を考慮すると、広範囲の撮影にあたり多視点他角度の画像を準備するのは、非効率ともいえてしまう。
% カメラは歪みのないPinholeカメラモデルで撮影し、Field of Viewは70°、画素解像度は800x800である。トータルの画像は90枚である。

To focus on the effects of refraction, we conduct our experiments in a simulation-based environment, thereby isolating the influences of other phenomena such as surface reflections and light attenuation in water. 
We acknowledge that these factors are non-negligible in real-world scenarios, and thus constitute a limitation of our current study.
First, we create a detailed mesh representing a riverbed by applying a displacement modifier to a gravel texture within Blender. 
This dataset is then used to generate physically accurate rendered images using Blender Cycles, a path-tracing renderer.
We assume a flat, distortion-free refractive surface (the water surface). 
The average water depth is set to 10 meters.
The scene is captured from multiple viewpoints. 
We acquire images with 85\% side and forward overlap, primarily focusing on the riverbed from a nadir view. 
Additionally, we capture images by circling around the center of the riverbed at off-nadir angles of 20° and 40°. 
While these multi-view conditions are advantageous for geometry estimation methods like Gaussian Splatting, they also introduce challenges. 
As illustrated in \cref{fig:space_compression_by_view}, larger observation angles to the refractive surface increase both object distortion and the discrepancy between the apparent and true positions, making the removal of refractive effects more difficult. 
Conversely, from a practical standpoint, preparing multi-view, multi-angle images for a wide area can be inefficient.
The images are captured using a distortion-free pinhole camera model with a 70° field of view and a resolution of 800x800 pixels. 
The total number of images is 90, except images for the evaluation from novel views.
Overview of a condition for capturing is shown in \cref{fig:simulator-settings}.
% 撮影条件がなぜ有利であり、同時に課題でもあるのかを論じている部分は、少し議論が長すぎるかもしれない。この考察は「Introduction」や、提案手法を説明する「Method」セクションで、問題設定の動機付けとして述べた方が、話の流れがスムーズになるだろう。実験セクションは、あくまで「何を行ったか」を客観的かつ簡潔に記述する場だからだ。


\subsection{Implementation}\label{sec:implementation}
We implement our Refractive-Aware Gaussian Splatting by extending the open-source gsplat \parencite{ye2025_gsplat} framework, a highly GPU-optimized library for various Gaussian Splatting methods. 
The parameter transformation that models refraction from the camera's viewpoint is implemented as a custom autograd function in PyTorch \parencite{paszke2019pytorch}. 
This allows for seamless integration into gsplat's differentiable rasterizer and parameter optimization pipeline. 
To solve the quartic equation (\cref{eq:quartic-s}) for the center correction described in \cref{center-correction}, we employ the Newton-Raphson method. 
This process is parallelized on the GPU using PyTorch, resulting in a modest computational overhead (at most 3x slower than the original gsplat implementation of 3DGS \parencite{Kerbl2023ToG_3DGS}).

For the optimization process, we adopt the adaptive density control from the vanilla 3DGS \parencite{Kerbl2023ToG_3DGS} and use its default hyperparameters. 
The optimization is run for 30,000 iterations. 
To simplify the implementation of explicit gradient calculations, we constrain the spherical harmonic (SH) degree of the Gaussians to 0, meaning they only store a base color and are view-independent. 
While standard 3DGS typically initializes the Gaussians from a sparse point cloud generated by an SfM pipeline like COLMAP \parencite{schoenberger2016_colmap}, it may be difficult to detect enough keypoints for a textureless beds. 
Therefore, we initialize the Gaussians as a planar point cloud positioned at the approximate water depth of 10 meters. 
All experiments are conducted on a single NVIDIA RTX 3090 GPU.
% SfMが屈折シーンでは失敗するため、平面点群で初期化した、という記述は非常に重要だ。しかし、この主張は極めて強い。可能であれば、実際にCOLMAPをこのシーンに適用した際の失敗例（例えば、歪んだ点群やカメラポーズ推定の失敗）を補足資料（Supplementary Material）で示す

\subsection{Geometry Extraction}\label{sec:geometry-extraction}

\begin{figure}[htbp]
  \centering
  \captionsetup{justification=raggedright,singlelinecheck=false}

  % 左
  \begin{minipage}[t]{0.25\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/experiment/flow_pc_extraction.png}
    \caption{Flow Chart of Point Cloud Extraction.}\label{fig:flow_pc_extraction}
  \end{minipage}
  \hfill
  % 右
  \begin{minipage}[t]{0.7\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/experiment/extraction.png}
    \caption{Our geometry extraction pipeline. 
    Left: The initial noisy point cloud converted from 3DGS.
    Center: The point cloud is discretized into a 2D grid, and the median height is computed for each cell.
    Top-right: The resulting 2.5D height map.
    Bottom-right: The final surface-aligned point cloud generated from the height map.}
    \label{fig:extract_surface_aligned_pc}
  \end{minipage}
\end{figure}


To quantitatively evaluate geometric accuracy, the 3D Gaussian Splatting (3DGS) model must be converted into a standard 3D representation. 
For this study, we aim to extract a dense point cloud that is precisely aligned with the surface, which is appropriate for our target scenes, such as seabeds and riverbeds.
While several sophisticated methods have been proposed to enhance the geometric fidelity of 3DGS, including SuGaR \parencite{Gu2024CVPR_SuGaR}, 2DGS \parencite{Huang2024SIGGRAPH_2DGS}, and TrimGS \parencite{fan2024_trimGS}, we adopt a simple extraction method due to its ease of implementation.

First, we convert the 3DGS data into a raw point cloud using 3DGS-to-PC \parencite{stuart20253dgstopcconvert3dgaussian}. 
The core idea of this method is to sample points from each Gaussian ellipsoid in proportion to its volume, which generates a dense point cloud. 
However, this point cloud often contains significant noise and floaters artifacts inherent to volumetric sampling. 
To address this, we perform outlier removal by fitting a local plane to the neighbors of each point within a specified radius and culling points that are distant from this plane. 
This process is implemented using open-source point cloud library CloudCompare \parencite{girardeau2016cloudcompare} (v2.6.2).

Next, as illustrated in \cref{fig:extract_surface_aligned_pc}, the filtered point cloud is discretized into a 2D grid on the horizontal plane.
The grid resolution is intentionally set finer than that of our quantitative evaluation metrics to preserve high-frequency surface details. 
For each grid cell, we determine its elevation by calculating the median height of all points falling within the corresponding vertical column. 
This procedure yields a height map. 
Finally, a surface-aligned point cloud is generated by placing a point at the center of each grid cell at its computed median elevation. 
It is crucial to note that the quality of the final output is sensitive to parameters like the outlier filtering radius and the grid size, which must be carefully tuned for each specific dataset.
% 「シンプルで実装が容易な手法を採用する」という主張は明確で良い。しかし、なぜ既存の高度な手法（SuGaRなど）を使わないのか、その理由付けをもう少し強化しよう。"ease of implementation" に加えて、「我々の対象（海底・河床）はハイトマップで十分に表現できる単純なサーフェスであり、複雑なトポロジーを扱う汎用的な手法は過剰スペックである」といった正当性を加えると、手法選択の説得力が増す。


