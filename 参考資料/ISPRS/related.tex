\section{Literature Review}\label{RELATED}
\sloppy

Bathymetry in shallow water area has been explored through a variety of methodologies \cite{He2024_survey-shallow-bathymetry}.
Traditional fields measurements methods with bathymetric rods or hammers, and global positioning systems (GPS) are extremely time-consuming and dangerous.
Shipborne sonar systems are a representative method of bathymetry, however, the operation is restricted due to its narrow scanning swath. % 引用をつける
Therefore, remote sensing that reconstructs underwater morphology from data observed in the air is valuable in this field.
As remote sensing for shallow bathymetry, platforms equipped with sensors are generally classified into satellite, airborne, and, UAV-based systems.
The sensors employed range from RGB cameras and multi/hyper-spectral cameras, to LiDAR and even Synthetic Aperture Radar (SAR).
As an efficient, inexpensive, safe, and accessible solution, Our work focuses on methods based on UAV-based RGB imagery.
% radiometric な手法に関して言及すべき?

To reconstruct 3D information from UAV imagery, previous works have employed geometric approaches such as Structure-from-Motion (SfM) \cite{schoenberger2016_colmap} or Multi-View-Stereo (MVS) \cite{Furukawa2010_PatchMVS,Furukawa2015_MVS},
which have been developed in the computer vision community.
In a typical incremental SfM pipeline, keypoints are firstly detected and matched across frames using feature detectors and descriptors such as SIFT \cite{Lowe2004_SIFT}.
Fundamental matrix $F$ between two images is then calculated, commonly via eight-points algorithm \cite{Hartley1997_8PointAlgorithm} combined with random sample consensus (RANSAC) \cite{Fischler1987_RANSAC}, which lead to camera pose recovery through singular value decomposition.
New camera poses are iteratively registered via Perspective-n-Point algorithms, which align estimated 3D points with 2D features in new frames.
Triangulation is subsequently applied to obtain additional 3D points from feature correspondences, and bundle adjustment (BA) \cite{Triggs2000_BA} is finally performed to minimize reprojection error, refining both camera parameters and 3D points. 
MVS builds upon the calibrated cameras estimated from SfM, computing dense per-pixel depth and normal maps across views, which are then fused into a dense 3D point cloud or mesh.

This entire pipeline assumes straight-line traveling of light, while in reality, refraction at water-air interface significantly degrades both SfM and MVS reconstructions.
This refractive distortion represents the key challenge in photogrammetric bathymetry. 
% Previous studies (and also our method) have attempted to address this issue under simplifying assumptions, such as high water clarity, minimal surface waves, calm water conditions, and textured visible beds.
\cite{Woodget2014_PhotograBathy-multiply-n} demonstrated the potential of photogrammetric bathymetry from UAV imagery, applying a simple refraction correction by multiplying refractive index to SfM software outputs.
\cite{Dietrich2016_multi-angle-correction} proposed multi-angle refraction correction based on the pixel ray angle and estimating 3D points, which consider the view-angle dependence of each apparent points. 
However, this method only corrects for vertical displacement, ignoring horizontal distortions.
\cite{Makris2024_refractive-aware-sfm} successfully integrated refraction modeling directly into the SfM pipeline, avoiding post-hoc or iterative correction. 
This R-SfM method enables highly accurate camera pose estimation and point clouds generation.
They combine Deep Learning method \cite{Alevizos2022_DL-shallow-bathymetry} to compensate the sparseness of SfM output, however, Deep Learning based method needs extensive training datasets and remain highly site-dependent.



